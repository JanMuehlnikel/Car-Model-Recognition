{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Simple CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from utils import load_images\n",
    "from utils import TrainingPlot\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from utils import load_images\n",
    "from utils import TrainingPlot\n",
    "\n",
    "clear_session()\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = \"_cnn_1.1\"\n",
    "\n",
    "METADATA = pd.read_csv('../src/meta_data.csv')\n",
    "IMAGE_FOLDER = \"../src/final_data\"\n",
    "\n",
    "PARAMETERS = {\n",
    "    \"MODEL_VERSION\": MODEL_VERSION,\n",
    "    \"IMG_HEIGHT\": 128,\n",
    "    \"IMG_WIDTH\": 128,\n",
    "    \"NUM_CLASSES\": 19,\n",
    "    \"TEST_SPLIT\": 0.2,\n",
    "    \"BATCH_SIZE\": 128,\n",
    "    \"EPOCHS\": 15,\n",
    "    }\n",
    "\n",
    "#with open(f\"../src/models/resNet50/{MODEL_VERSION}/parameters{MODEL_VERSION}.json\", \"w\") as json_file:\n",
    "#    json.dump(PARAMETERS, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 57141/57141 [08:47<00:00, 108.39it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    METADATA = pd.read_csv('../src/meta_data.csv')\n",
    "\n",
    "    # Load images and labels\n",
    "    image_folder = '../src/final_data'\n",
    "    images, labels = load_images(image_folder, METADATA, PARAMETERS[\"IMG_HEIGHT\"], PARAMETERS[\"IMG_WIDTH\"])\n",
    "\n",
    "    # Normalize images\n",
    "    images = images / 255.0\n",
    "\n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "    # Train / Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "    del images\n",
    "    del labels\n",
    "    del labels_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "input_shape = (PARAMETERS[\"IMG_HEIGHT\"], PARAMETERS[\"IMG_WIDTH\"], 3)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=12, \n",
    "                    validation_split=0.3, \n",
    "                    batch_size=32,\n",
    "                    callbacks=[TrainingPlot(PARAMETERS[\"MODEL_VERSION\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"../src/models/model_v{PARAMETERS[\"MODEL_VERSION\"]}.h5\")\n",
    "model.save(f\"../src/models/model_v{PARAMETERS[\"MODEL_VERSION\"]}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    # Evaluate the model\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU:0\"):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1\n",
    "    y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predicted labels to string representation\n",
    "y_pred_labels = [label_mapping[label] for label in y_pred_class]\n",
    "\n",
    "# decode encoded labes to numeric values and convert the to the string representations again\n",
    "y_test_numeric = np.argmax(y_test, axis=1)\n",
    "y_test_labels = [label_mapping[label] for label in y_test_numeric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report:')\n",
    "classification_report_str = classification_report(y_test_labels, y_pred_labels)\n",
    "print(classification_report_str)\n",
    "\n",
    "with open(f'../src/models/cnn/{PARAMETERS[\"MODEL_VERSION\"]}/classification_report_{PARAMETERS[\"MODEL_VERSION\"]}.txt', 'w') as f:\n",
    "    f.write('Classification Report:\\n')\n",
    "    f.write(classification_report_str)\n",
    "    f.write(f'\\nAccuracy: {test_accuracy}\\n')\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(22, 16))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='', cmap='Blues', \n",
    "            xticklabels=label_mapping.values(), yticklabels=label_mapping.values())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.savefig(f\"../src/models/cnn/{PARAMETERS[\"MODEL_VERSION\"]}/conf_matrix_{PARAMETERS[\"MODEL_VERSION\"]}.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del images\n",
    "del labels\n",
    "del label_encoder\n",
    "del labels_encoded\n",
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CarModelEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
